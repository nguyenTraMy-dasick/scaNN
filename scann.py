# -*- coding: utf-8 -*-
"""ScaNN (reloaded).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NkHVsclkvCQW6ATgzMi6rGPf_ZOZp_uH

# CELL 1: INSTALLATION & SETUP
"""

# ============================================================================
# CELL 1: INSTALLATION & SETUP
# ============================================================================

print("Installing required packages...")

# Uninstall conflicting packages
!pip uninstall -y tensorflow keras scann numpy ml-dtypes protobuf tensorboard jax jaxlib

# Install specific versions for compatibility (same as working code)
!pip install numpy==1.26.4 tensorflow==2.16.2 scann==1.3.1 keras==3.3.3 ml-dtypes==0.3.2 protobuf==4.25.8 tensorboard==2.16.2

# Uninstall jax/jaxlib again (important!)
!pip uninstall -y jax jaxlib

# Install additional dependencies
!pip install sentence-transformers scikit-learn matplotlib pillow tqdm datasets

print("\n" + "=" * 70)
print("Installation complete!")
print("=" * 70)

"""# CELL 2: COMPLETE INPUT COLLECTION"""

# ============================================================================
# CELL 2: COMPLETE INPUT COLLECTION
# ============================================================================

import gc
import numpy as np
import matplotlib.pyplot as plt

print("=" * 70)
print("INPUT COLLECTION")
print("=" * 70)

# Step 1: Get query type and content
print("\nWhat would you like to search for?")
print("  1. Upload an image to find similar images")
print("  2. Enter text to find similar documents")

query_mode = input("\nEnter your choice (1 or 2): ").strip()

if query_mode == "1":
    # IMAGE QUERY
    print("\nPlease upload your query image:")
    from google.colab import files
    uploaded = files.upload()
    query_image_path = list(uploaded.keys())[0]

    SEARCH_TYPE = "image"
    print("\nDetected: IMAGE SEARCH")

    # Display query image immediately
    from PIL import Image
    query_img = Image.open(query_image_path)
    plt.figure(figsize=(4, 4))
    plt.imshow(query_img)
    plt.title("Your Query Image", fontweight='bold', fontsize=12)
    plt.axis('off')
    plt.show()

elif query_mode == "2":
    # TEXT QUERY
    query_text = input("\nEnter your search query: ").strip()

    if not query_text:
        raise ValueError("Query text cannot be empty!")

    SEARCH_TYPE = "text"
    print("\nDetected: TEXT SEARCH")
    print(f'Query: "{query_text}"')

else:
    raise ValueError("Invalid choice! Please enter 1 or 2.")

# Step 2: Get K value
K = int(input("\nHow many similar results do you want to find (K): "))
if K <= 0 or K > 10000:
    raise ValueError(f"K must be between 1 and 10000")

print("\n" + "=" * 70)
print(f"INPUT COMPLETE!")
print(f"  Search type: {SEARCH_TYPE.upper()}")
print(f"  K value: {K}")
print(f"Starting automatic dataset loading and search...")
print("=" * 70)

gc.collect()

"""# CELL 3: STREAMING PIPELINE (Load + Extract Features)"""

# ============================================================================
# CELL 3: STREAMING PIPELINE (Load + Extract Features)
# ============================================================================

import numpy as np
import gc
import tensorflow as tf
from datasets import load_dataset
from tqdm import tqdm
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image as keras_image
from PIL import Image

print("=" * 70)
print(f"STREAMING PIPELINE: LOAD & EXTRACT FEATURES ({SEARCH_TYPE.upper()})")
print("=" * 70)

# Storage for visualization (RAM efficient thumbnails)
dataset_visuals = []
feature_vectors = []

# Configuration
MAX_SAMPLES = 5000
BATCH_SIZE = 128

if SEARCH_TYPE == "image":
    print("\n[Init] Setting up ResNet50 Pipeline...")
    from tensorflow.keras.applications import ResNet50
    from tensorflow.keras.applications.resnet50 import preprocess_input

    # Load Model
    model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

    # Batch processing function
    def process_batch(images):
        processed_imgs = []
        for img in images:
            if img.mode != 'RGB':
                img = img.convert('RGB')
            img_model = img.resize((224, 224), Image.Resampling.LANCZOS)
            processed_imgs.append(keras_image.img_to_array(img_model))
        return preprocess_input(np.array(processed_imgs))

    print(f"\n[Processing] Loading ImageNet-Sketch (Streaming)...")
    dataset = load_dataset("vaughankraska/imagenet_sketch", split="train", streaming=True)

    batch_images = []
    pbar = tqdm(total=MAX_SAMPLES, desc="Processing images")
    count = 0

    for item in dataset:
        if count >= MAX_SAMPLES:
            break

        img = item['image']
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # Store thumbnail (100x100 for visualization)
        img_thumb = img.resize((100, 100))
        dataset_visuals.append(np.array(img_thumb, dtype=np.uint8))

        # Accumulate for batch processing
        batch_images.append(img)
        count += 1

        # Process batch and extract features
        if len(batch_images) == BATCH_SIZE:
            batch_input = process_batch(batch_images)
            batch_features = model.predict(batch_input, verbose=0)
            feature_vectors.append(batch_features)

            batch_images = []
            gc.collect()
            pbar.update(BATCH_SIZE)

    # Process final batch
    if batch_images:
        batch_input = process_batch(batch_images)
        batch_features = model.predict(batch_input, verbose=0)
        feature_vectors.append(batch_features)
        pbar.update(len(batch_images))

    pbar.close()

    # Concatenate feature arrays
    feature_vectors = np.vstack(feature_vectors)

    # Extract Query Image
    print("\n[Query] Extracting query image features...")
    q_img = keras_image.load_img(query_image_path, target_size=(224, 224))
    q_arr = np.expand_dims(keras_image.img_to_array(q_img), axis=0)
    q_arr = preprocess_input(q_arr)
    query_vector = model.predict(q_arr, verbose=0)

    del model
    tf.keras.backend.clear_session()

elif SEARCH_TYPE == "text":
    print(f"\n[Processing] Loading Text Dataset...")
    from sentence_transformers import SentenceTransformer

    device = 'cuda' if tf.config.list_physical_devices('GPU') else 'cpu'
    model = SentenceTransformer('paraphrase-MiniLM-L6-v2', device=device)

    # Try MS MARCO, fallback to AG News
    try:
        print("Attempting to load MS MARCO passages...")
        dataset = load_dataset("ms_marco", "v2.1", split="train", streaming=True)

        all_texts = []
        count = 0

        print(f"Sampling {MAX_SAMPLES} passages...")
        for item in tqdm(dataset, total=MAX_SAMPLES, desc="Loading texts"):
            if count >= MAX_SAMPLES:
                break

            # MS MARCO structure: item has 'passages' dict with 'passage_text' list
            if 'passages' in item and 'passage_text' in item['passages']:
                passages = item['passages']['passage_text']
                if passages and len(passages) > 0:
                    text = passages[0]  # Take first passage
                    if text and len(text) > 50:  # Filter short texts
                        all_texts.append(text)
                        count += 1
            elif 'passage' in item:
                text = item['passage']
                if text and len(text) > 50:
                    all_texts.append(text)
                    count += 1

        if len(all_texts) < 100:
            raise ValueError("MS MARCO loaded too few samples, using fallback")

        print(f"\nSuccessfully loaded {len(all_texts)} MS MARCO passages")

    except Exception as e:
        print(f"\nMS MARCO loading failed: {str(e)}")
        print("Falling back to AG News dataset...")

        dataset = load_dataset("ag_news", split="train")
        all_texts = [item['text'] for item in dataset]

        print(f"Loaded {len(all_texts)} AG News articles")

    # Store text for visualization
    dataset_visuals = all_texts

    # Encode documents
    print(f"\nEncoding {len(all_texts)} documents...")
    feature_vectors = model.encode(
        all_texts,
        batch_size=256,
        show_progress_bar=True,
        convert_to_numpy=True
    )

    # Encode query
    print("Encoding query...")
    query_vector = model.encode([query_text], convert_to_numpy=True)

    del model

gc.collect()

print(f"\n" + "=" * 70)
print("PIPELINE COMPLETE")
print("=" * 70)
print(f"Dataset size: {len(dataset_visuals):,}")
print(f"Features shape: {feature_vectors.shape}")
print(f"Query shape: {query_vector.shape}")
print(f"Memory: ~{feature_vectors.nbytes / (1024**2):.1f} MB")

# Display sample
if SEARCH_TYPE == "text":
    print("\nSample passages:")
    for i in range(min(3, len(dataset_visuals))):
        print(f"\n{i+1}. {dataset_visuals[i][:200]}...")
else:
    print("\nDisplaying sample images:")
    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    for i, ax in enumerate(axes.flat):
        ax.imshow(dataset_visuals[i])
        ax.axis('off')
        ax.set_title(f"Image {i}", fontsize=9)
    plt.suptitle("Sample Images from Dataset", fontsize=12, fontweight='bold')
    plt.tight_layout()
    plt.show()

"""# CELL 4: LINEAR SEARCH BASELINE"""

# ============================================================================
# CELL 4: LINEAR SEARCH BASELINE
# ============================================================================

import numpy as np
import time
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity
from math import ceil

print("=" * 70)
print("LINEAR SEARCH (Brute-Force Baseline)")
print("=" * 70)

print(f"\nSearching through {len(feature_vectors):,} vectors...")
start_time = time.time()
similarities = cosine_similarity(query_vector, feature_vectors)[0]
linear_indices = np.argsort(-similarities)[:K]
linear_time = time.time() - start_time

print(f"Search completed in {linear_time*1000:.2f} ms")

# Display results
print(f"\nTop-{K} results from Linear Search:")

if SEARCH_TYPE == "image":
    cols = 5
    rows = ceil(K / cols)
    fig = plt.figure(figsize=(cols * 2.5, rows * 2.5))

    for i, idx in enumerate(linear_indices):
        plt.subplot(rows, cols, i + 1)
        plt.imshow(dataset_visuals[idx])
        plt.title(f"Rank {i+1}\nSim={similarities[idx]:.3f}", fontsize=9)
        plt.axis('off')

    plt.suptitle(f"Linear Search: Top-{K} Similar Images",
                 fontsize=12, fontweight='bold')
    plt.tight_layout()
    plt.show()

else:
    for i, idx in enumerate(linear_indices[:min(K, 10)]):
        print(f"\n{i+1}. Similarity: {similarities[idx]:.4f}")
        print(f"   {dataset_visuals[idx][:200]}...")

# Store baseline
linear_baseline = {
    'indices': linear_indices,
    'time': linear_time,
    'similarities': similarities[linear_indices]
}

print("\n" + "=" * 70)
print(f"BASELINE: {linear_time*1000:.2f} ms | 100% accuracy")
print("=" * 70)

gc.collect()

"""# CELL 5: BUILD AND TEST ScaNN MODELS"""

# ============================================================================
# CELL 5: BUILD ScaNN MODELS (NO SEARCHING YET)
# ============================================================================

import scann
import numpy as np
import time

print("=" * 70)
print("BUILDING ScaNN MODELS")
print("=" * 70)

# Normalize vectors
print("\nNormalizing vectors for dot product similarity...")
feature_vectors_norm = feature_vectors / np.linalg.norm(feature_vectors, axis=1, keepdims=True)
query_vector_norm = query_vector / np.linalg.norm(query_vector, axis=1, keepdims=True)

# ScaNN configurations
scann_configs = [
    {
        'name': 'ScaNN-Fast',
        'description': 'Fastest search, lower accuracy',
        'num_leaves': 100,
        'num_leaves_to_search': 10,
        'reordering': 0
    },
    {
        'name': 'ScaNN-Balanced',
        'description': 'Balanced speed and accuracy',
        'num_leaves': 200,
        'num_leaves_to_search': 20,
        'reordering': int(K * 2)
    },
    {
        'name': 'ScaNN-Accurate',
        'description': 'Higher accuracy, slower',
        'num_leaves': 400,
        'num_leaves_to_search': 40,
        'reordering': int(K * 5)
    },
    {
        'name': 'ScaNN-Precision',
        'description': 'Maximum accuracy',
        'num_leaves': 600,
        'num_leaves_to_search': 60,
        'reordering': int(K * 10)
    }
]

# Build models ONLY (no searching)
scann_models = {}

for i, config in enumerate(scann_configs):
    print(f"\n[{i+1}/4] Building {config['name']}...")
    print(f"    {config['description']}")

    # Build index
    builder = scann.scann_ops_pybind.builder(
        feature_vectors_norm, K, "dot_product"
    ).tree(
        num_leaves=config['num_leaves'],
        num_leaves_to_search=config['num_leaves_to_search'],
        training_sample_size=min(len(feature_vectors_norm), 10000)
    )

    if config['reordering'] > 0:
        builder = builder.score_ah(2, anisotropic_quantization_threshold=0.2)
        searcher = builder.reorder(config['reordering']).build()
    else:
        searcher = builder.score_brute_force().build()

    # Store model
    scann_models[config['name']] = {
        'searcher': searcher,
        'config': config
    }

    print(f"    Built successfully")

print("\n" + "=" * 70)
print("All 4 ScaNN models built!")
print("=" * 70)

gc.collect()

"""# CELL 6: VISUALIZE ScaNN RESULTS

"""

# ============================================================================
# CELL 6: K-VALUE ANALYSIS (SINGLE SOURCE OF TRUTH)
# ============================================================================

import numpy as np
import time
from sklearn.metrics.pairwise import cosine_similarity

print("=" * 70)
print("ANALYZING PERFORMANCE ACROSS K VALUES")
print("=" * 70)

# Smart K value selection using geometric progression (base 2)
def generate_smart_k_values(user_k, max_k):
    """
    Generate K values as geometric progression with ratio 2
    STOPS when reaching user_k, then adds user_k

    Example:
      user_k=500 -> [1, 2, 4, 8, 16, 32, 64, 128, 256, 500]
      user_k=100 -> [1, 2, 4, 8, 16, 32, 64, 100]
      user_k=50  -> [1, 2, 4, 8, 16, 32, 50]
    """
    k_values = []
    current = 1

    while current < user_k:
        k_values.append(current)
        current *= 2

    k_values.append(user_k)
    return k_values

k_values = generate_smart_k_values(K, len(feature_vectors))

print(f"\nUser selected K: {K}")
print(f"Testing K values: {k_values}")
print(f"Total tests: {len(k_values)} K values x 5 methods = {len(k_values) * 5} searches")
print(f"Estimated time: ~{len(k_values) * 5 * 0.05:.0f} seconds")

# Storage
perf_data = {
    'k_values': k_values,
    'linear': {'times': [], 'recalls': []},
}

for config in scann_configs:
    perf_data[config['name']] = {'times': [], 'recalls': []}

# ALSO store results at user's K for later use
scann_results = []

# Test each K
from tqdm import tqdm
print("\n" + "-" * 70)

for k_idx, k in enumerate(tqdm(k_values, desc="Testing K values")):
    # Linear search
    start = time.time()
    sims = cosine_similarity(query_vector, feature_vectors)[0]
    linear_idx_k = np.argsort(-sims)[:k]
    linear_t = time.time() - start

    perf_data['linear']['times'].append(linear_t * 1000)
    perf_data['linear']['recalls'].append(100.0)

    # ScaNN models
    for config in scann_configs:
        model_name = config['name']
        searcher = scann_models[model_name]['searcher']

        start = time.time()
        neighbors, distances = searcher.search_batched(query_vector_norm, final_num_neighbors=k)
        scann_t = time.time() - start

        # Calculate recall
        found = set(neighbors[0])
        gt = set(linear_idx_k)
        recall = len(found & gt) / k * 100

        perf_data[model_name]['times'].append(scann_t * 1000)
        perf_data[model_name]['recalls'].append(recall)

        # Store results at user's K for visualization
        if k == K:
            result = {
                'name': model_name,
                'indices': neighbors[0],
                'distances': distances[0],
                'time': scann_t,
                'recall': recall / 100,  # Convert to 0-1 range
                'speedup': linear_t / scann_t
            }
            scann_results.append(result)

print("\n" + "=" * 70)
print("K-VALUE ANALYSIS COMPLETE")
print("=" * 70)

# Summary table
print(f"\n{'K Value':<10} {'Linear (ms)':<15} {'Best ScaNN':<20} {'Speedup':<10}")
print("-" * 70)

for i, k in enumerate(k_values):
    linear_time = perf_data['linear']['times'][i]

    # Find best ScaNN time
    scann_times = [perf_data[name]['times'][i] for name in [c['name'] for c in scann_configs]]
    best_scann_time = min(scann_times)
    best_scann_name = [c['name'] for c in scann_configs
                       if perf_data[c['name']]['times'][i] == best_scann_time][0]

    speedup = linear_time / best_scann_time
    marker = " <-" if k == K else ""

    print(f"{k:<10} {linear_time:<15.2f} {best_scann_name:<20} {speedup:<10.1f}x{marker}")

print("=" * 70)

# CONSISTENCY CHECK
print("\n" + "=" * 70)
print("RESULTS AT USER'S K")
print("=" * 70)
print(f"{'Config':<20} {'Time (ms)':<12} {'Recall':<12} {'Speedup':<10}")
print("-" * 70)

k_idx = k_values.index(K)
print(f"{'Linear Search':<20} {perf_data['linear']['times'][k_idx]:<12.2f} {'100.0%':<12} {'1.00x':<10}")

for res in scann_results:
    print(f"{res['name']:<20} {res['time']*1000:<12.2f} {res['recall']*100:<11.1f}% {res['speedup']:<10.2f}x")

print("=" * 70)

gc.collect()

"""# CELL 7: K-VALUE ANALYSIS"""

# ============================================================================
# CELL 7: VISUALIZE ScaNN RESULTS
# ============================================================================

import matplotlib.pyplot as plt
from math import ceil

print("=" * 70)
print("ScaNN RESULTS VISUALIZATION")
print("=" * 70)

# Select configuration
print("\nAvailable configurations:")
for i, res in enumerate(scann_results):
    print(f"  {i+1}. {res['name']} - Recall: {res['recall']*100:.1f}%, Time: {res['time']*1000:.2f}ms")

config_choice = int(input(f"\nSelect config to visualize (1-{len(scann_results)}): ")) - 1
selected = scann_results[config_choice]

print(f"\nShowing results from: {selected['name']}")

# Display results
if SEARCH_TYPE == "image":
    cols = 5
    rows = ceil(K / cols)
    plt.figure(figsize=(cols * 2.5, rows * 2.5))

    for i, idx in enumerate(selected['indices']):
        plt.subplot(rows, cols, i + 1)
        plt.imshow(dataset_visuals[idx])

        # Mark correct/incorrect
        is_correct = idx in linear_baseline['indices']
        color = 'green' if is_correct else 'red'

        # Handle NaN distances (use cosine similarity instead)
        if np.isnan(selected['distances'][i]):
            # Compute cosine similarity as fallback
            score = np.dot(query_vector_norm[0], feature_vectors_norm[idx])
        else:
            score = selected['distances'][i]

        plt.title(f"#{i+1}\nScore={score:.3f}",
                  fontsize=9, color=color)
        plt.axis('off')

        # Border
        ax = plt.gca()
        for spine in ax.spines.values():
            spine.set_edgecolor(color)
            spine.set_linewidth(3)

    plt.suptitle(f"{selected['name']}: Top-{K} Results\n" +
                 f"Recall: {selected['recall']*100:.1f}% | Time: {selected['time']*1000:.2f}ms",
                 fontsize=12, fontweight='bold')
    plt.tight_layout()
    plt.show()

else:
    print(f"\nTop-{K} results:")
    for i, idx in enumerate(selected['indices']):
        is_correct = idx in linear_baseline['indices']
        marker = "CORRECT" if is_correct else "INCORRECT"

        # Handle NaN distances
        if np.isnan(selected['distances'][i]):
            score = np.dot(query_vector_norm[0], feature_vectors_norm[idx])
        else:
            score = selected['distances'][i]

        print(f"\n{marker} - {i+1}. Score: {score:.4f}")
        print(f"   {dataset_visuals[idx][:200]}...")

print("\n" + "=" * 70)

"""# CELL 8: PERFORMANCE VISUALIZATION"""

# ============================================================================
# CELL 8: PERFORMANCE VISUALIZATION
# ============================================================================

import matplotlib.pyplot as plt
import numpy as np

print("=" * 70)
print("GENERATING PERFORMANCE VISUALIZATIONS")
print("=" * 70)

colors = {
    'Linear Search (Exact)': '#e74c3c',
    'ScaNN-Fast': '#3498db',
    'ScaNN-Balanced': '#2ecc71',
    'ScaNN-Accurate': '#f39c12',
    'ScaNN-Precision': '#9b59b6'
}

# Figure 1: Time and Recall vs K
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Query Time vs K
ax1.plot(perf_data['k_values'], perf_data['linear']['times'],
         marker='o', linewidth=2.5, markersize=8,
         label='Linear Search', color=colors['Linear Search (Exact)'])

for config in scann_configs:
    ax1.plot(perf_data['k_values'], perf_data[config['name']]['times'],
             marker='s', linewidth=2.5, markersize=8,
             label=config['name'], color=colors[config['name']])

ax1.set_xlabel('K (Number of Neighbors)', fontsize=11, fontweight='bold')
ax1.set_ylabel('Query Time (ms)', fontsize=11, fontweight='bold')
ax1.set_title('Query Time vs K', fontsize=13, fontweight='bold')
ax1.legend(loc='best', fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_yscale('log')

# Plot 2: Recall vs K
for config in scann_configs:
    ax2.plot(perf_data['k_values'], perf_data[config['name']]['recalls'],
             marker='s', linewidth=2.5, markersize=8,
             label=config['name'], color=colors[config['name']])

ax2.axhline(y=100, color=colors['Linear Search (Exact)'],
            linestyle='--', linewidth=2, label='Linear (100%)')
ax2.set_xlabel('K (Number of Neighbors)', fontsize=11, fontweight='bold')
ax2.set_ylabel('Recall@K (%)', fontsize=11, fontweight='bold')
ax2.set_title('Recall@K vs K', fontsize=13, fontweight='bold')
ax2.legend(loc='best', fontsize=9)
ax2.grid(True, alpha=0.3)
ax2.set_ylim([80, 105])

plt.tight_layout()
plt.show()

# Figure 2: Speedup Comparison
fig, ax = plt.subplots(figsize=(10, 5))

k_idx = perf_data['k_values'].index(K)
linear_t = perf_data['linear']['times'][k_idx]

speedups = []
names = []
bar_colors = []

for config in scann_configs:
    scann_t = perf_data[config['name']]['times'][k_idx]
    speedups.append(linear_t / scann_t)
    names.append(config['name'])
    bar_colors.append(colors[config['name']])

bars = ax.barh(names, speedups, color=bar_colors, edgecolor='black', linewidth=2)

for bar, speedup in zip(bars, speedups):
    width = bar.get_width()
    ax.text(width + 0.3, bar.get_y() + bar.get_height()/2,
            f'{speedup:.2f}x', ha='left', va='center',
            fontsize=10, fontweight='bold')

ax.set_xlabel('Speedup vs Linear Search', fontsize=11, fontweight='bold')
ax.set_title(f'Speedup Comparison (K={K})',
             fontsize=13, fontweight='bold')
ax.grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.show()

print("\nVisualizations complete!")
print("=" * 70)

"""# CELL 9: SUMMARY AND EXPORT"""

# ============================================================================
# CELL 9: SUMMARY AND EXPORT
# ============================================================================

import numpy as np
import pandas as pd
from datetime import datetime

print("=" * 70)
print("FINAL PERFORMANCE SUMMARY")
print("=" * 70)

# Statistics table
print("\n" + "=" * 80)
print(f"{'Configuration':<20} {'Avg Time':<12} {'Min Recall':<12} {'Max Speedup':<12}")
print("=" * 80)

linear_avg = np.mean(perf_data['linear']['times'])
print(f"{'Linear Search':<20} {linear_avg:<12.2f} {'100.0%':<12} {'1.00x':<12}")

for config in scann_configs:
    times = perf_data[config['name']]['times']
    recalls = perf_data[config['name']]['recalls']

    avg_time = np.mean(times)
    min_recall = np.min(recalls)
    max_speedup = np.max([linear_avg / t for t in times])

    print(f"{config['name']:<20} {avg_time:<12.2f} {min_recall:<11.1f}% {max_speedup:<12.2f}x")

print("=" * 80)

# Key insights
print("\nKEY INSIGHTS:")
print("-" * 70)

best_speed = min(scann_configs, key=lambda c: np.mean(perf_data[c['name']]['times']))
best_speedup = linear_avg / np.mean(perf_data[best_speed['name']]['times'])
print(f"1. FASTEST: {best_speed['name']} achieves {best_speedup:.2f}x speedup")

best_acc = max(scann_configs, key=lambda c: np.mean(perf_data[c['name']]['recalls']))
best_recall = np.mean(perf_data[best_acc['name']]['recalls'])
print(f"2. MOST ACCURATE: {best_acc['name']} maintains {best_recall:.1f}% avg recall")

print(f"\n3. DATASET SIZE: {len(feature_vectors):,} {SEARCH_TYPE}s")
print(f"4. VECTOR DIMENSION: {feature_vectors.shape[1]}")

# Memory usage
print("\nMEMORY USAGE:")
print("-" * 70)
vector_mb = feature_vectors.nbytes / (1024**2)
print(f"Feature vectors: {vector_mb:.2f} MB")
print(f"ScaNN indices: ~{vector_mb * 1.05:.2f} - {vector_mb * 1.15:.2f} MB (+5-15% overhead)")

# Export to CSV
print("\nExporting results to CSV...")

results_data = []
for i, k in enumerate(perf_data['k_values']):
    results_data.append({
        'Config': 'Linear Search',
        'K': k,
        'Time_ms': perf_data['linear']['times'][i],
        'Recall_%': 100.0,
        'Speedup': 1.0
    })

    for config in scann_configs:
        linear_t = perf_data['linear']['times'][i]
        scann_t = perf_data[config['name']]['times'][i]

        results_data.append({
            'Config': config['name'],
            'K': k,
            'Time_ms': scann_t,
            'Recall_%': perf_data[config['name']]['recalls'][i],
            'Speedup': linear_t / scann_t
        })

df = pd.DataFrame(results_data)
csv_file = f"scann_results_{SEARCH_TYPE}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
df.to_csv(csv_file, index=False)

print(f"Saved to: {csv_file}")

print("\n" + "=" * 70)
print("ANALYSIS COMPLETE!")
print("=" * 70)